{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1fdddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import IPython\n",
    "import sklearn #Machine Learning package\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba29881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Dataset\n",
    "\n",
    "df = pd.read_csv ('Peak_matching_Campylobacter.csv') #Import the peak matching table as a dataframe\n",
    "Y = df['AMR'] # Target variable will be the AMR pattern (what you want to predict)\n",
    "X = df.drop(columns=['AMR','ID']) #MALDI peaks and their intensities are feature set (The AMR and ID columns are discarded)\n",
    "saved_cols = X.columns #store columns names in this variable\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca350b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features transformation/Scaling\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler() #Store the function in the scaler variable\n",
    "scaled = scaler.fit_transform(X) #transformed values into the (0,1) range\n",
    "\n",
    "scaled_df = pd.DataFrame(scaled, Y, columns = saved_cols) #Create a new dataframe with the scaled intensities\n",
    "scaled_df = scaled_df.reset_index() \n",
    "\n",
    "scaled_df.loc[scaled_df['AMR'].str.contains('Cip'), 'AMR'] = '1' # it will transform all label containing the string \"Cip\" into 1 (1 = resistant)\n",
    "scaled_df.loc[~scaled_df['AMR'].str.contains('1'), 'AMR'] = '0' # it will transform all label NOT containing the string \"1\" into 0 (0 = susceptible)\n",
    "\n",
    "scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ca580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = scaled_df['AMR'].astype(float) # Need to convert categorical to numerical type value\n",
    "X = scaled_df.drop(columns=['AMR']) \n",
    "\n",
    "print(scaled_df.groupby('AMR').size()) # A total of 183 CipR and 157 susceptible strains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c33cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features selection\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = RandomForestClassifier(random_state=10, n_estimators=300) \n",
    "clf = clf.fit(X, Y)\n",
    "\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "X_new  = model.transform(X)\n",
    "\n",
    "print(\"Before Feature selection\",X.shape) # Before and After the features selection\n",
    "print(\"After Feature selection\",X_new.shape)\n",
    "\n",
    "scaled_features_df = pd.DataFrame(X_new, Y) #Create a new dataframe with the scaled intensities\n",
    "\n",
    "features = X.columns.values\n",
    "print(features[model.get_support()]) # Features of interest retained for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84c4e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training/Validation/Test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_rem, Y_train, Y_rem = train_test_split(X_new, Y, test_size=0.3,stratify=Y,random_state=0, shuffle=True) # Split the dataset into a 70/30 training/test set based on the AMR label\n",
    "\n",
    "X_valid, X_test, Y_valid, Y_test = train_test_split(X_rem,Y_rem, test_size=0.5)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c0ac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model selection\n",
    "\n",
    "from sklearn.metrics import plot_roc_curve, roc_curve, auc, precision_recall_curve, plot_precision_recall_curve, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Fitting different models to the training data\n",
    "\n",
    "LR = LogisticRegression().fit(X_train, Y_train) \n",
    "NB = GaussianNB().fit (X_train, Y_train)\n",
    "RF = RandomForestClassifier().fit(X_train,Y_train)\n",
    "\n",
    "#ROC Curve\n",
    "\n",
    "classifiers = [LR, NB, RF]\n",
    "ax = plt.gca()\n",
    "for i in classifiers:\n",
    "    plot_roc_curve(i, X_valid, Y_valid, ax=ax)\n",
    "    plt.plot([0,1], [0,1], ':',linewidth=1.4, c='k')\n",
    "    plt.legend(bbox_to_anchor = (1.05, 0.6))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf415d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision-Recall curve\n",
    "\n",
    "classifiers1 = [LR, NB, RF]\n",
    "ax = plt.gca()\n",
    "for i in classifiers1 :\n",
    "    plot_precision_recall_curve(i, X_valid, Y_valid, ax=ax)\n",
    "    plt.legend(bbox_to_anchor = (1.8, 0.6))\n",
    "    \n",
    "for z in classifiers1 :\n",
    "    precision, recall, thresholds = precision_recall_curve(Y_test, z.predict_proba(X_test)[:,1])\n",
    "    area = auc(recall, precision)\n",
    "    print(\"AUPRC\",area)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c853068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tune the model: Grid Search\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Design the grid of parameters you want to investigate\n",
    "\n",
    "param_grid = {\n",
    "'max_depth': [80, 90, 100, 110],\n",
    "'max_features': [2, 3],\n",
    "'min_samples_leaf': [3, 4, 5],\n",
    "'min_samples_split': [8, 10, 12],\n",
    "'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "\n",
    "RF = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(estimator = RF, param_grid = param_grid, cv= 10, n_jobs = -1, verbose = 2, scoring='f1') # Best parameters for the Random Forest model based on the F1 score\n",
    "grid_search.fit(X_valid, Y_valid)\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b12a8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance\n",
    "\n",
    "RF = RandomForestClassifier(max_depth=110, max_features=2, min_samples_leaf=3,min_samples_split=8, n_estimators=200).fit (X_train, Y_train) # Fit the model with the optimized hyperparameters\n",
    "\n",
    "#ROC Curve\n",
    "\n",
    "classifiers = [RF]\n",
    "ax = plt.gca()\n",
    "for i in classifiers:\n",
    "    plot_roc_curve(i, X_valid, Y_valid, ax=ax)\n",
    "    plt.plot([0,1], [0,1], ':',linewidth=1.4, c='k')\n",
    "    plt.legend(bbox_to_anchor = (1.05, 0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84853ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision-Recall curve\n",
    "\n",
    "classifiers1 = [RF]\n",
    "ax = plt.gca()\n",
    "for i in classifiers1 :\n",
    "    plot_precision_recall_curve(i, X_valid, Y_valid, ax=ax)\n",
    "    plt.legend(bbox_to_anchor = (1.8, 0.6))\n",
    "    \n",
    "# Compute Precision-Recall and plot curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(Y_test, RF.predict_proba(X_test)[:,1])\n",
    "area = auc(recall, precision)\n",
    "\n",
    "print(\"AUPRC\",area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6f06ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimization of the Model\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#Metrics\n",
    "\n",
    "y_pred_rf=RF.predict(X_valid)\n",
    "confusion = confusion_matrix(Y_valid,y_pred_rf)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion, display_labels=RF.classes_).plot()\n",
    "plt.tick_params(axis=u'both', which=u'both',length=0)\n",
    "\n",
    "precision= precision_score(Y_valid, y_pred_rf)\n",
    "recall=recall_score(Y_valid, y_pred_rf)\n",
    "F1= f1_score(Y_valid, y_pred_rf)\n",
    "print('F1-score:',F1)\n",
    "print('Precision:',precision)\n",
    "print('Recall:',recall)\n",
    "\n",
    "total1=sum(sum(confusion))\n",
    "accuracy1=(confusion[0,0]+confusion[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "specificity1 = confusion[0,0]/(confusion[0,0]+confusion[0,1])\n",
    "print('Specificity : ', specificity1 )\n",
    "sensitivity1 = confusion[1,1]/(confusion[1,0]+confusion[1,1])\n",
    "print('Sensitivity : ', sensitivity1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7753f0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tune the model: Best threshold\n",
    "\n",
    "from numpy import arange\n",
    "from numpy import argmax\n",
    "from matplotlib import pyplot\n",
    "from numpy import sqrt\n",
    "\n",
    "# predict probabilities\n",
    "yhat = RF.predict_proba(X_valid)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "yhat = yhat[:, 1]\n",
    "\n",
    "# calculate roc curves\n",
    "precision, recall, thresholds = precision_recall_curve(Y_valid, yhat)\n",
    "\n",
    "# convert to f score\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "# locate the index of the largest f score\n",
    "ix = argmax(fscore)\n",
    "print('Best Threshold=%f, F-Score=%.3f' % (thresholds[ix], fscore[ix]))\n",
    "\n",
    "# plot the roc curve for the model\n",
    "no_skill = len(Y_valid[Y_valid==1]) / len(Y_valid)\n",
    "pyplot.plot([0,1], [no_skill,no_skill], linestyle='--', label='No Skill')\n",
    "pyplot.plot(recall, precision, marker='.', label='Logistic')\n",
    "pyplot.scatter(recall[ix], precision[ix], marker='o', color='black', label='Best')\n",
    "\n",
    "# axis labels\n",
    "pyplot.xlabel('Recall')\n",
    "pyplot.ylabel('Precision')\n",
    "pyplot.legend()\n",
    "\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7cf30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the new threshold\n",
    "\n",
    "y_pred_new_threshold = (RF.predict_proba(X_valid)[:,1]>=0.337941).astype(int)\n",
    "\n",
    "#Metrics\n",
    "\n",
    "confusion = confusion_matrix(Y_valid,y_pred_new_threshold )\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion, display_labels=RF.classes_).plot()\n",
    "plt.tick_params(axis=u'both', which=u'both',length=0)\n",
    "precision= precision_score(Y_valid, y_pred_new_threshold)\n",
    "recall=recall_score(Y_valid, y_pred_new_threshold)\n",
    "F1= f1_score(Y_valid, y_pred_new_threshold)\n",
    "print('F1-score:',F1)\n",
    "print('Precision/PPV:',precision)\n",
    "print('Recall:',recall)\n",
    "\n",
    "\n",
    "total1=sum(sum(confusion))\n",
    "accuracy1=(confusion[0,0]+confusion[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "specificity1 = confusion[0,0]/(confusion[0,0]+confusion[0,1])\n",
    "print('Specificity : ', specificity1 )\n",
    "sensitivity1 = confusion[1,1]/(confusion[1,0]+confusion[1,1])\n",
    "print('Sensitivity : ', sensitivity1)\n",
    "NPV = confusion[0,0]/(confusion[0,0]+confusion[1,0])\n",
    "print('NPV: ', NPV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e3c5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation of the tuned model on the test set\n",
    "\n",
    "y_pred_new_threshold = (RF.predict_proba(X_test)[:,1]>=0.337941).astype(int)\n",
    "\n",
    "#Metrics\n",
    "\n",
    "confusion = confusion_matrix(Y_test,y_pred_new_threshold )\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion, display_labels=RF.classes_).plot()\n",
    "plt.tick_params(axis=u'both', which=u'both',length=0)\n",
    "precision= precision_score(Y_test, y_pred_new_threshold)\n",
    "recall=recall_score(Y_test, y_pred_new_threshold)\n",
    "F1= f1_score(Y_test, y_pred_new_threshold)\n",
    "print('F1-score:',F1)\n",
    "print('Precision/PPV:',precision)\n",
    "print('Recall:',recall)\n",
    "\n",
    "\n",
    "total1=sum(sum(confusion))\n",
    "accuracy1=(confusion[0,0]+confusion[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "specificity1 = confusion[0,0]/(confusion[0,0]+confusion[0,1])\n",
    "print('Specificity : ', specificity1 )\n",
    "sensitivity1 = confusion[1,1]/(confusion[1,0]+confusion[1,1])\n",
    "print('Sensitivity : ', sensitivity1)\n",
    "NPV = confusion[0,0]/(confusion[0,0]+confusion[1,0])\n",
    "print('NPV: ', NPV)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee9bc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction\n",
    "\n",
    "Unknown = pd.read_csv ('List_of_Unknow_Spectra.csv') # import the unknow spectra you want classify (they need to have the same features than the one used for the training)\n",
    "prediction = (RF.predict_proba(Unknown)[:,1]>=0.359180).astype(int) #Will predict the class (0 or 1)\n",
    "\n",
    "print(\"Prediction\",prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7780beb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
